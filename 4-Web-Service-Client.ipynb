{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Service Client\n",
    "\n",
    "En este notebook vamos a consumir un servicio de machine learning. El servicio debe ser levantando con el script server.py por separado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import check_random_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EJERCICIO 1: \n",
    "\n",
    "Modifique el server.py para que acepte requests por GET. Modifique el codigo del cliente para enviar los datos por GET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Prediccion': 0}\n"
     ]
    }
   ],
   "source": [
    "url = \"http://127.0.0.1:1080/predict\"\n",
    "# DEFINA SU CLIENTE GET AQUI:\n",
    "# Parametros del modelo\n",
    "parameters = {\n",
    "    \"petal_length\": \"1.1\",\n",
    "    \"sepal_length\": \"1\",\n",
    "    \"petal_width\": \"4.5\",\n",
    "    \"sepal_width\": \"1\"\n",
    "}\n",
    "\n",
    "# enviamos los datos por GET\n",
    "response = requests.get(url, params=parameters)\n",
    "\n",
    "# imprimimos el mensaje\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EJERCICIO 2:\n",
    "\n",
    "* Entrene un modelo de machine learning con MNIST y salve su modelo en un archivo pickle. [https://scikit-learn.org/stable/auto_examples/linear_model/plot_sparse_logistic_regression_mnist.html]\n",
    "* Modifique el server.py para que agregue la ruta /predict-number y que sea capaz de predecir si una imagen pertecene a un numero del 0 al 9\n",
    "* Va a enviar la imagen desde el cliente (este notebook) como un base64 hacia el server.py\n",
    "* el server.py va recibir la imagen la reconstruye en una imagen nuevamente y la manda al modelo de ML\n",
    "* la imagen que ingresa al server.py debe salvarla en un folder (images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, penalty='l1', solver='saga', tol=0.1)"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "# Author: Arthur Mensch <arthur.mensch@m4x.org>\n",
    "# License: BSD 3 clause\n",
    "\n",
    "# Turn down for faster convergence\n",
    "t0 = time.time()\n",
    "train_samples = 5000\n",
    "\n",
    "# Load data from https://www.openml.org/d/554\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)\n",
    "\n",
    "random_state = check_random_state(0)\n",
    "permutation = random_state.permutation(X.shape[0])\n",
    "X = X[permutation]\n",
    "y = y[permutation]\n",
    "X = X.reshape((X.shape[0], -1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=train_samples, test_size=10000)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Turn up tolerance for faster convergence\n",
    "mnist_model = LogisticRegression(\n",
    "    C=50. / train_samples, penalty='l1', solver='saga', tol=0.1\n",
    ")\n",
    "mnist_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pkl_filename = \"ModeloMNIST.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(mnist_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Prediccion': 0}\n"
     ]
    }
   ],
   "source": [
    "# DEFINA SU CLIENTE POST AQUI:\n",
    "img = {'image': open('img/9.png', 'rb')}\n",
    "r = requests.post(url, files=img)\n",
    "\n",
    "print(r.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}